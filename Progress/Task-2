# Task 2: Scrape infobox for all movies in List of Disney Films (save as list of dictionaries

# import librabries and packages
from bs4 import BeautifulSoup as bs
import requests


# get link
webpage = requests.get('https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films')
soup = bs(webpage.content, "lxml")

# define function to get the contents
def get_content_value(row):
    if row.find("li"):
        return [li.get_text(" ", strip=True).replace("\xa0", " ") for li in row.find_all("li")]
    elif row.find("br"):
        return [text for text in row.stripped_strings]
    else:
        return row.get_text(" ", strip=True).replace("\xa0", " ")

# Task 3.1: Strip out all references ([1],[2],etc) from HTML
def clean_tags(soup):
    for tag in soup.find_all(["sup", "span"]):
        tag.decompose()
  
# scrape movie info box into a dict
def get_info_box(url):
    r = requests.get(url)
    soup = bs(r.content)
    info_box = soup.find(class_="infobox vevent")
    rows = info_box.find_all("tr")
    
    clean_tags(soup)

    movie_info = {}
    for index, row in enumerate(rows):
        if index == 0:
            movie_info['title'] = row.find("th").get_text(" ", strip=True).title()
        else:
            if row.find('th'):
                content_key = row.find("th").get_text(" ", strip=True)
                content_value = get_content_value(row.find("td"))
                movie_info[content_key] = content_value
            
    return movie_info

movies = soup.select(".wikitable.sortable i a")
base_path = "https://en.wikipedia.org/"

movies_info = []
for index, movie in enumerate(movies):
    try:
        relative_path = movie['href']
        full_path = base_path + relative_path
        title = movie['title']
        
        movies_info.append(get_info_box(full_path))
        
    except Exception as e:
        pass

# Save & Load dataset checkpoint (JSON file)
import json

def save_data_json(title, data):
    with open(title, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
        
def load_data_json(title):
    with open(title, encoding="utf-8") as f:
        return json.load(f)
        
save_data_json("disney_movies_data.json", movies_info)
movies_info = load_data_json("disney_movies_data.json")
        
